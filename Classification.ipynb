{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Q0i7zmYHA_nA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from torch import nn\n",
        "import sklearn\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "gO3urQ2KA_nD",
        "outputId": "ab5d48a1-b266-4da8-bf0a-c787d2858a51"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>X3</th>\n",
              "      <th>X4</th>\n",
              "      <th>X5</th>\n",
              "      <th>X6</th>\n",
              "      <th>X7</th>\n",
              "      <th>X8</th>\n",
              "      <th>X9</th>\n",
              "      <th>X10</th>\n",
              "      <th>...</th>\n",
              "      <th>X1529</th>\n",
              "      <th>X1530</th>\n",
              "      <th>X1531</th>\n",
              "      <th>X1532</th>\n",
              "      <th>X1533</th>\n",
              "      <th>X1534</th>\n",
              "      <th>X1535</th>\n",
              "      <th>X1536</th>\n",
              "      <th>Labels</th>\n",
              "      <th>Names</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.007448</td>\n",
              "      <td>0.005253</td>\n",
              "      <td>-0.009571</td>\n",
              "      <td>-0.028665</td>\n",
              "      <td>-0.009832</td>\n",
              "      <td>0.010781</td>\n",
              "      <td>-0.013981</td>\n",
              "      <td>-0.012602</td>\n",
              "      <td>-0.006386</td>\n",
              "      <td>-0.009895</td>\n",
              "      <td>...</td>\n",
              "      <td>0.068188</td>\n",
              "      <td>-0.019846</td>\n",
              "      <td>-0.000020</td>\n",
              "      <td>0.020169</td>\n",
              "      <td>-0.013200</td>\n",
              "      <td>-0.008383</td>\n",
              "      <td>-0.012673</td>\n",
              "      <td>-0.021548</td>\n",
              "      <td>2</td>\n",
              "      <td>Nap. Hortex mix ll D 2 x2,47 4,94D</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.001597</td>\n",
              "      <td>0.002713</td>\n",
              "      <td>-0.009045</td>\n",
              "      <td>-0.018641</td>\n",
              "      <td>-0.015243</td>\n",
              "      <td>0.011046</td>\n",
              "      <td>-0.015525</td>\n",
              "      <td>-0.007528</td>\n",
              "      <td>-0.006158</td>\n",
              "      <td>-0.034086</td>\n",
              "      <td>...</td>\n",
              "      <td>0.056998</td>\n",
              "      <td>-0.008058</td>\n",
              "      <td>0.001550</td>\n",
              "      <td>0.023570</td>\n",
              "      <td>-0.018883</td>\n",
              "      <td>-0.020884</td>\n",
              "      <td>-0.028633</td>\n",
              "      <td>-0.023261</td>\n",
              "      <td>7</td>\n",
              "      <td>ChipTopPap Ceb170g D 1 x3.99 3,99D</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.006266</td>\n",
              "      <td>0.010816</td>\n",
              "      <td>-0.017970</td>\n",
              "      <td>-0.036862</td>\n",
              "      <td>-0.011562</td>\n",
              "      <td>0.009155</td>\n",
              "      <td>-0.037920</td>\n",
              "      <td>-0.011867</td>\n",
              "      <td>-0.012057</td>\n",
              "      <td>-0.031627</td>\n",
              "      <td>...</td>\n",
              "      <td>0.055361</td>\n",
              "      <td>-0.012993</td>\n",
              "      <td>-0.002356</td>\n",
              "      <td>0.023761</td>\n",
              "      <td>0.010863</td>\n",
              "      <td>-0.004231</td>\n",
              "      <td>-0.016777</td>\n",
              "      <td>-0.036293</td>\n",
              "      <td>3</td>\n",
              "      <td>Orz.Arach.Fel.140g D 2 x6,39 12,78D</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.010780</td>\n",
              "      <td>-0.016283</td>\n",
              "      <td>-0.010780</td>\n",
              "      <td>0.002203</td>\n",
              "      <td>-0.028427</td>\n",
              "      <td>0.011609</td>\n",
              "      <td>-0.017380</td>\n",
              "      <td>-0.011993</td>\n",
              "      <td>0.001167</td>\n",
              "      <td>-0.032073</td>\n",
              "      <td>...</td>\n",
              "      <td>0.058444</td>\n",
              "      <td>-0.013782</td>\n",
              "      <td>-0.008196</td>\n",
              "      <td>0.014967</td>\n",
              "      <td>-0.017037</td>\n",
              "      <td>-0.028646</td>\n",
              "      <td>-0.001387</td>\n",
              "      <td>-0.021354</td>\n",
              "      <td>4</td>\n",
              "      <td>Soskowiczkix980g B 1 x9,99 9,99B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.004790</td>\n",
              "      <td>-0.004190</td>\n",
              "      <td>-0.029838</td>\n",
              "      <td>-0.017892</td>\n",
              "      <td>-0.027329</td>\n",
              "      <td>0.025215</td>\n",
              "      <td>-0.031638</td>\n",
              "      <td>-0.029538</td>\n",
              "      <td>-0.002323</td>\n",
              "      <td>-0.034530</td>\n",
              "      <td>...</td>\n",
              "      <td>0.053485</td>\n",
              "      <td>-0.015042</td>\n",
              "      <td>0.012274</td>\n",
              "      <td>0.018901</td>\n",
              "      <td>-0.012519</td>\n",
              "      <td>-0.010405</td>\n",
              "      <td>-0.017810</td>\n",
              "      <td>-0.020347</td>\n",
              "      <td>5</td>\n",
              "      <td>JogBr-MaTwvi370g D 1 x3,49 3,49D</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1538 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         X1        X2        X3        X4        X5        X6        X7  \\\n",
              "0 -0.007448  0.005253 -0.009571 -0.028665 -0.009832  0.010781 -0.013981   \n",
              "1 -0.001597  0.002713 -0.009045 -0.018641 -0.015243  0.011046 -0.015525   \n",
              "2  0.006266  0.010816 -0.017970 -0.036862 -0.011562  0.009155 -0.037920   \n",
              "3  0.010780 -0.016283 -0.010780  0.002203 -0.028427  0.011609 -0.017380   \n",
              "4  0.004790 -0.004190 -0.029838 -0.017892 -0.027329  0.025215 -0.031638   \n",
              "\n",
              "         X8        X9       X10  ...     X1529     X1530     X1531     X1532  \\\n",
              "0 -0.012602 -0.006386 -0.009895  ...  0.068188 -0.019846 -0.000020  0.020169   \n",
              "1 -0.007528 -0.006158 -0.034086  ...  0.056998 -0.008058  0.001550  0.023570   \n",
              "2 -0.011867 -0.012057 -0.031627  ...  0.055361 -0.012993 -0.002356  0.023761   \n",
              "3 -0.011993  0.001167 -0.032073  ...  0.058444 -0.013782 -0.008196  0.014967   \n",
              "4 -0.029538 -0.002323 -0.034530  ...  0.053485 -0.015042  0.012274  0.018901   \n",
              "\n",
              "      X1533     X1534     X1535     X1536  Labels  \\\n",
              "0 -0.013200 -0.008383 -0.012673 -0.021548       2   \n",
              "1 -0.018883 -0.020884 -0.028633 -0.023261       7   \n",
              "2  0.010863 -0.004231 -0.016777 -0.036293       3   \n",
              "3 -0.017037 -0.028646 -0.001387 -0.021354       4   \n",
              "4 -0.012519 -0.010405 -0.017810 -0.020347       5   \n",
              "\n",
              "                                 Names  \n",
              "0   Nap. Hortex mix ll D 2 x2,47 4,94D  \n",
              "1   ChipTopPap Ceb170g D 1 x3.99 3,99D  \n",
              "2  Orz.Arach.Fel.140g D 2 x6,39 12,78D  \n",
              "3     Soskowiczkix980g B 1 x9,99 9,99B  \n",
              "4     JogBr-MaTwvi370g D 1 x3,49 3,49D  \n",
              "\n",
              "[5 rows x 1538 columns]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_excel(\"Train.xlsx\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBkbw-KJdDkb",
        "outputId": "0caa8844-dd4f-44c2-9503-2b68214b0d33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           X1       X2        X3        X4        X5        X6        X7  \\\n",
            "410  0.007803 -0.01498 -0.006283  0.009724 -0.013859  0.011031 -0.015646   \n",
            "\n",
            "           X8        X9       X10  ...    X1529     X1530     X1531     X1532  \\\n",
            "410 -0.036575 -0.007563 -0.022929  ...  0.05597 -0.035855  0.001247  0.000218   \n",
            "\n",
            "       X1533     X1534     X1535     X1536  Labels  \\\n",
            "410 -0.00297 -0.021649 -0.012819 -0.026117       5   \n",
            "\n",
            "                                   Names  \n",
            "410  Jog. naturalny bio 200g 1x3,49 3,49  \n",
            "\n",
            "[1 rows x 1538 columns]\n"
          ]
        }
      ],
      "source": [
        "row = df.loc[df['Names'] == \"Jog. naturalny bio 200g 1x3,49 3,49\"]\n",
        "print(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "D6uReMa9A_nD",
        "outputId": "27ddf11c-5d77-4449-e538-79f7af9e9610"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>X3</th>\n",
              "      <th>X4</th>\n",
              "      <th>X5</th>\n",
              "      <th>X6</th>\n",
              "      <th>X7</th>\n",
              "      <th>X8</th>\n",
              "      <th>X9</th>\n",
              "      <th>X10</th>\n",
              "      <th>...</th>\n",
              "      <th>X1527</th>\n",
              "      <th>X1528</th>\n",
              "      <th>X1529</th>\n",
              "      <th>X1530</th>\n",
              "      <th>X1531</th>\n",
              "      <th>X1532</th>\n",
              "      <th>X1533</th>\n",
              "      <th>X1534</th>\n",
              "      <th>X1535</th>\n",
              "      <th>X1536</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.007448</td>\n",
              "      <td>0.005253</td>\n",
              "      <td>-0.009571</td>\n",
              "      <td>-0.028665</td>\n",
              "      <td>-0.009832</td>\n",
              "      <td>0.010781</td>\n",
              "      <td>-0.013981</td>\n",
              "      <td>-0.012602</td>\n",
              "      <td>-0.006386</td>\n",
              "      <td>-0.009895</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.003741</td>\n",
              "      <td>-0.036654</td>\n",
              "      <td>0.068188</td>\n",
              "      <td>-0.019846</td>\n",
              "      <td>-0.000020</td>\n",
              "      <td>0.020169</td>\n",
              "      <td>-0.013200</td>\n",
              "      <td>-0.008383</td>\n",
              "      <td>-0.012673</td>\n",
              "      <td>-0.021548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.001597</td>\n",
              "      <td>0.002713</td>\n",
              "      <td>-0.009045</td>\n",
              "      <td>-0.018641</td>\n",
              "      <td>-0.015243</td>\n",
              "      <td>0.011046</td>\n",
              "      <td>-0.015525</td>\n",
              "      <td>-0.007528</td>\n",
              "      <td>-0.006158</td>\n",
              "      <td>-0.034086</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.005093</td>\n",
              "      <td>-0.008427</td>\n",
              "      <td>0.056998</td>\n",
              "      <td>-0.008058</td>\n",
              "      <td>0.001550</td>\n",
              "      <td>0.023570</td>\n",
              "      <td>-0.018883</td>\n",
              "      <td>-0.020884</td>\n",
              "      <td>-0.028633</td>\n",
              "      <td>-0.023261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.006266</td>\n",
              "      <td>0.010816</td>\n",
              "      <td>-0.017970</td>\n",
              "      <td>-0.036862</td>\n",
              "      <td>-0.011562</td>\n",
              "      <td>0.009155</td>\n",
              "      <td>-0.037920</td>\n",
              "      <td>-0.011867</td>\n",
              "      <td>-0.012057</td>\n",
              "      <td>-0.031627</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001084</td>\n",
              "      <td>-0.011786</td>\n",
              "      <td>0.055361</td>\n",
              "      <td>-0.012993</td>\n",
              "      <td>-0.002356</td>\n",
              "      <td>0.023761</td>\n",
              "      <td>0.010863</td>\n",
              "      <td>-0.004231</td>\n",
              "      <td>-0.016777</td>\n",
              "      <td>-0.036293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.010780</td>\n",
              "      <td>-0.016283</td>\n",
              "      <td>-0.010780</td>\n",
              "      <td>0.002203</td>\n",
              "      <td>-0.028427</td>\n",
              "      <td>0.011609</td>\n",
              "      <td>-0.017380</td>\n",
              "      <td>-0.011993</td>\n",
              "      <td>0.001167</td>\n",
              "      <td>-0.032073</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018216</td>\n",
              "      <td>0.003838</td>\n",
              "      <td>0.058444</td>\n",
              "      <td>-0.013782</td>\n",
              "      <td>-0.008196</td>\n",
              "      <td>0.014967</td>\n",
              "      <td>-0.017037</td>\n",
              "      <td>-0.028646</td>\n",
              "      <td>-0.001387</td>\n",
              "      <td>-0.021354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.004790</td>\n",
              "      <td>-0.004190</td>\n",
              "      <td>-0.029838</td>\n",
              "      <td>-0.017892</td>\n",
              "      <td>-0.027329</td>\n",
              "      <td>0.025215</td>\n",
              "      <td>-0.031638</td>\n",
              "      <td>-0.029538</td>\n",
              "      <td>-0.002323</td>\n",
              "      <td>-0.034530</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.013037</td>\n",
              "      <td>-0.000955</td>\n",
              "      <td>0.053485</td>\n",
              "      <td>-0.015042</td>\n",
              "      <td>0.012274</td>\n",
              "      <td>0.018901</td>\n",
              "      <td>-0.012519</td>\n",
              "      <td>-0.010405</td>\n",
              "      <td>-0.017810</td>\n",
              "      <td>-0.020347</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1536 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         X1        X2        X3        X4        X5        X6        X7  \\\n",
              "0 -0.007448  0.005253 -0.009571 -0.028665 -0.009832  0.010781 -0.013981   \n",
              "1 -0.001597  0.002713 -0.009045 -0.018641 -0.015243  0.011046 -0.015525   \n",
              "2  0.006266  0.010816 -0.017970 -0.036862 -0.011562  0.009155 -0.037920   \n",
              "3  0.010780 -0.016283 -0.010780  0.002203 -0.028427  0.011609 -0.017380   \n",
              "4  0.004790 -0.004190 -0.029838 -0.017892 -0.027329  0.025215 -0.031638   \n",
              "\n",
              "         X8        X9       X10  ...     X1527     X1528     X1529     X1530  \\\n",
              "0 -0.012602 -0.006386 -0.009895  ... -0.003741 -0.036654  0.068188 -0.019846   \n",
              "1 -0.007528 -0.006158 -0.034086  ... -0.005093 -0.008427  0.056998 -0.008058   \n",
              "2 -0.011867 -0.012057 -0.031627  ... -0.001084 -0.011786  0.055361 -0.012993   \n",
              "3 -0.011993  0.001167 -0.032073  ... -0.018216  0.003838  0.058444 -0.013782   \n",
              "4 -0.029538 -0.002323 -0.034530  ... -0.013037 -0.000955  0.053485 -0.015042   \n",
              "\n",
              "      X1531     X1532     X1533     X1534     X1535     X1536  \n",
              "0 -0.000020  0.020169 -0.013200 -0.008383 -0.012673 -0.021548  \n",
              "1  0.001550  0.023570 -0.018883 -0.020884 -0.028633 -0.023261  \n",
              "2 -0.002356  0.023761  0.010863 -0.004231 -0.016777 -0.036293  \n",
              "3 -0.008196  0.014967 -0.017037 -0.028646 -0.001387 -0.021354  \n",
              "4  0.012274  0.018901 -0.012519 -0.010405 -0.017810 -0.020347  \n",
              "\n",
              "[5 rows x 1536 columns]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_df = df.iloc[:, 0:1536]\n",
        "X_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "e6JuzVXYA_nE",
        "outputId": "12cd5064-be37-433c-8884-80b3d4090e9f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Labels</th>\n",
              "      <th>Names</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>Nap. Hortex mix ll D 2 x2,47 4,94D</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>ChipTopPap Ceb170g D 1 x3.99 3,99D</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Orz.Arach.Fel.140g D 2 x6,39 12,78D</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Soskowiczkix980g B 1 x9,99 9,99B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>JogBr-MaTwvi370g D 1 x3,49 3,49D</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Labels                                Names\n",
              "0       2   Nap. Hortex mix ll D 2 x2,47 4,94D\n",
              "1       7   ChipTopPap Ceb170g D 1 x3.99 3,99D\n",
              "2       3  Orz.Arach.Fel.140g D 2 x6,39 12,78D\n",
              "3       4     Soskowiczkix980g B 1 x9,99 9,99B\n",
              "4       5     JogBr-MaTwvi370g D 1 x3,49 3,49D"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_df = df[[\"Labels\", \"Names\"]]  # Include both \"Labels\" and \"Names\" columns\n",
        "Y_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "58oklkcTA_nE"
      },
      "outputs": [],
      "source": [
        "X = torch.tensor(X_df.values, dtype=torch.float)\n",
        "Y_labels = torch.tensor(Y_df[\"Labels\"].values, dtype=torch.long)  # Labels as long tensor\n",
        "Y_names = Y_df[\"Names\"].values  # Names as numpy array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "O-PoMmM4Rr5g"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "# Split the dataset into features (X) and labels (Y_labels) with shuffling\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Get the indices of train and test sets\n",
        "train_indices = list(range(len(y_train)))\n",
        "test_indices = list(range(len(y_train), len(y_train) + len(y_test)))\n",
        "\n",
        "# Assign the corresponding names to train and test sets\n",
        "Y_train_names = Y_names[train_indices]\n",
        "Y_test_names = Y_names[test_indices]\n",
        "\n",
        "Y_names_connected = np.concatenate((Y_train_names, Y_test_names), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OjIcTGq1A_nF",
        "outputId": "93ac01ec-f3a3-4455-f504-d7d087069856"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "7uUO4VhXA_nF"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.to(device)\n",
        "X_test = X_test.to(device)\n",
        "y_train = y_train.to(device)\n",
        "y_test = y_test.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "me_91TOMA_nF",
        "outputId": "0d0fa6b4-5c23-4861-aeb8-b79ec3be02fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=1536, out_features=1536, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
              "  (3): ReLU()\n",
              "  (4): Linear(in_features=1536, out_features=14, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_2 = nn.Sequential(\n",
        "    nn.Linear(in_features=1536, out_features=1536),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(in_features=1536, out_features=1536),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(in_features=1536, out_features=14),\n",
        ").to(device)\n",
        "\n",
        "model_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "E2oJ-R6hA_nG"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model_2.parameters(), lr=0.09)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsaCVx01A_nG",
        "outputId": "ae517aa0-bec8-4bfd-9504-39dc6b441385"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-2.5286e-02, -1.3138e-02, -5.8050e-04, -1.6630e-02, -1.3046e-03,\n",
              "          2.9025e-04, -1.4624e-02,  1.8874e-02,  7.6582e-03, -1.1054e-02,\n",
              "          7.8326e-03,  6.3940e-03,  1.6125e-02, -2.4292e-02],\n",
              "        [-2.6202e-02, -1.1178e-02, -1.8639e-03, -1.6370e-02,  1.2337e-03,\n",
              "          9.6744e-04, -1.4112e-02,  1.7811e-02,  4.7710e-03, -1.0247e-02,\n",
              "          6.9096e-03,  6.9399e-03,  1.7233e-02, -2.4549e-02],\n",
              "        [-2.4888e-02, -1.3680e-02, -1.4611e-03, -1.7591e-02, -2.9226e-04,\n",
              "         -1.3443e-05, -1.6774e-02,  1.9050e-02,  7.3396e-03, -1.1745e-02,\n",
              "          7.0849e-03,  7.5364e-03,  1.6672e-02, -2.4196e-02],\n",
              "        [-2.6838e-02, -1.1500e-02, -1.4500e-03, -1.6971e-02,  1.8987e-03,\n",
              "         -1.7693e-03, -1.3339e-02,  1.7987e-02,  6.0411e-03, -1.1580e-02,\n",
              "          4.5472e-03,  1.0427e-02,  1.5113e-02, -2.2905e-02],\n",
              "        [-2.5275e-02, -1.2144e-02, -1.5442e-03, -1.6350e-02, -4.1007e-04,\n",
              "          1.9209e-04, -1.3258e-02,  1.8310e-02,  5.2578e-03, -1.0837e-02,\n",
              "          7.5387e-03,  7.8866e-03,  1.6233e-02, -2.5289e-02],\n",
              "        [-2.6446e-02, -1.2860e-02, -3.4625e-03, -1.5166e-02, -5.0217e-04,\n",
              "          6.6259e-04, -1.6283e-02,  1.9324e-02,  6.8080e-03, -1.2113e-02,\n",
              "          6.3285e-03,  7.0802e-03,  1.5658e-02, -2.5711e-02],\n",
              "        [-2.5837e-02, -1.3606e-02, -2.5058e-03, -1.6070e-02, -2.6089e-04,\n",
              "          1.9874e-03, -1.5283e-02,  1.9510e-02,  6.2638e-03, -1.1987e-02,\n",
              "          4.8122e-03,  7.3695e-03,  1.6679e-02, -2.5014e-02],\n",
              "        [-2.5752e-02, -1.1969e-02, -3.6428e-05, -1.5694e-02, -1.8795e-03,\n",
              "          2.9184e-04, -1.5708e-02,  1.8117e-02,  6.8393e-03, -1.1089e-02,\n",
              "          8.3925e-03,  7.7815e-03,  1.7167e-02, -2.6258e-02],\n",
              "        [-2.5285e-02, -1.2839e-02,  5.0981e-05, -1.5884e-02, -2.2979e-04,\n",
              "          5.0390e-04, -1.4675e-02,  1.7951e-02,  6.2546e-03, -1.2809e-02,\n",
              "          7.7413e-03,  5.9107e-03,  1.6957e-02, -2.4191e-02],\n",
              "        [-2.8040e-02, -1.0776e-02, -1.1579e-03, -1.6985e-02,  9.4158e-04,\n",
              "          5.9784e-04, -1.2362e-02,  1.6549e-02,  7.3480e-03, -1.3008e-02,\n",
              "          5.2639e-03,  1.0391e-02,  1.5993e-02, -2.3109e-02]], device='cuda:0')"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_2.eval()\n",
        "with torch.inference_mode():\n",
        " y_logits = model_2(X_train)\n",
        " y_test_logits = model_2(X_test)\n",
        "y_logits[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nROZliH5A_nG",
        "outputId": "32aab585-4ac5-43da-dfea-e75c9f09a66b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-2.5286e-02, -1.3138e-02, -5.8050e-04, -1.6630e-02, -1.3046e-03,\n",
            "          2.9025e-04, -1.4624e-02,  1.8874e-02,  7.6582e-03, -1.1054e-02,\n",
            "          7.8326e-03,  6.3940e-03,  1.6125e-02, -2.4292e-02],\n",
            "        [-2.6202e-02, -1.1178e-02, -1.8639e-03, -1.6370e-02,  1.2337e-03,\n",
            "          9.6744e-04, -1.4112e-02,  1.7811e-02,  4.7710e-03, -1.0247e-02,\n",
            "          6.9096e-03,  6.9399e-03,  1.7233e-02, -2.4549e-02],\n",
            "        [-2.4888e-02, -1.3680e-02, -1.4611e-03, -1.7591e-02, -2.9226e-04,\n",
            "         -1.3443e-05, -1.6774e-02,  1.9050e-02,  7.3396e-03, -1.1745e-02,\n",
            "          7.0849e-03,  7.5364e-03,  1.6672e-02, -2.4196e-02],\n",
            "        [-2.6838e-02, -1.1500e-02, -1.4500e-03, -1.6971e-02,  1.8987e-03,\n",
            "         -1.7693e-03, -1.3339e-02,  1.7987e-02,  6.0411e-03, -1.1580e-02,\n",
            "          4.5472e-03,  1.0427e-02,  1.5113e-02, -2.2905e-02],\n",
            "        [-2.5275e-02, -1.2144e-02, -1.5442e-03, -1.6350e-02, -4.1007e-04,\n",
            "          1.9209e-04, -1.3258e-02,  1.8310e-02,  5.2578e-03, -1.0837e-02,\n",
            "          7.5387e-03,  7.8866e-03,  1.6233e-02, -2.5289e-02]], device='cuda:0')\n",
            "tensor([[0.0699, 0.0707, 0.0716, 0.0705, 0.0716, 0.0717, 0.0706, 0.0730, 0.0722,\n",
            "         0.0709, 0.0722, 0.0721, 0.0728, 0.0700],\n",
            "        [0.0698, 0.0709, 0.0715, 0.0705, 0.0718, 0.0717, 0.0707, 0.0730, 0.0720,\n",
            "         0.0709, 0.0722, 0.0722, 0.0729, 0.0699],\n",
            "        [0.0699, 0.0707, 0.0716, 0.0704, 0.0717, 0.0717, 0.0705, 0.0731, 0.0722,\n",
            "         0.0709, 0.0722, 0.0722, 0.0729, 0.0700],\n",
            "        [0.0698, 0.0709, 0.0716, 0.0705, 0.0718, 0.0716, 0.0707, 0.0730, 0.0721,\n",
            "         0.0709, 0.0720, 0.0724, 0.0728, 0.0701],\n",
            "        [0.0699, 0.0708, 0.0716, 0.0705, 0.0716, 0.0717, 0.0707, 0.0730, 0.0721,\n",
            "         0.0709, 0.0722, 0.0722, 0.0728, 0.0699]], device='cuda:0')\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(7, device='cuda:0')"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_probs = torch.softmax(y_logits, dim=1)\n",
        "y_test_pred_probs = torch.softmax(y_test_logits, dim=1)\n",
        "print(y_logits[:5])\n",
        "print(y_pred_probs[:5])\n",
        "torch.argmax(y_pred_probs[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "W7WRRU-8A_nG"
      },
      "outputs": [],
      "source": [
        "y_preds = torch.argmax(y_pred_probs, dim=1)\n",
        "y_test_preds = torch.argmax(y_test_pred_probs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "oI0AevhJA_nG"
      },
      "outputs": [],
      "source": [
        "def accuracy_fn(y_true, y_pred):\n",
        "  correct = torch.eq(y_true, y_pred).sum().item()\n",
        "  acc = (correct/len(y_pred)) * 100\n",
        "  return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZLEA2-RA_nH",
        "outputId": "567e877b-e893-467d-87ac-14927376cab8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 | Loss: 2.63718, Acc: 8.11% | Test loss: 2.63750, Test acc: 8.57\n",
            "Epoch: 100 | Loss: 2.53847, Acc: 23.63% | Test loss: 2.58636, Test acc: 17.14\n",
            "Epoch: 200 | Loss: 2.52318, Acc: 27.68% | Test loss: 2.58867, Test acc: 20.00\n",
            "Epoch: 300 | Loss: 2.51504, Acc: 34.13% | Test loss: 2.58496, Test acc: 26.67\n",
            "Epoch: 400 | Loss: 2.50096, Acc: 34.37% | Test loss: 2.57442, Test acc: 26.67\n",
            "Epoch: 500 | Loss: 2.46815, Acc: 36.75% | Test loss: 2.54863, Test acc: 25.71\n",
            "Epoch: 600 | Loss: 2.37126, Acc: 34.61% | Test loss: 2.47217, Test acc: 25.71\n",
            "Epoch: 700 | Loss: 2.13528, Acc: 30.31% | Test loss: 2.28056, Test acc: 27.62\n",
            "Epoch: 800 | Loss: 1.89413, Acc: 35.80% | Test loss: 2.06495, Test acc: 32.38\n",
            "Epoch: 900 | Loss: 1.72107, Acc: 39.38% | Test loss: 1.89802, Test acc: 35.24\n",
            "Epoch: 1000 | Loss: 1.58254, Acc: 45.82% | Test loss: 1.75856, Test acc: 40.95\n",
            "Epoch: 1100 | Loss: 1.45143, Acc: 53.70% | Test loss: 1.62240, Test acc: 44.76\n",
            "Epoch: 1200 | Loss: 1.31859, Acc: 60.86% | Test loss: 1.48211, Test acc: 50.48\n",
            "Epoch: 1300 | Loss: 1.18671, Acc: 65.16% | Test loss: 1.34413, Test acc: 57.14\n",
            "Epoch: 1400 | Loss: 1.06036, Acc: 68.50% | Test loss: 1.21583, Test acc: 59.05\n",
            "Epoch: 1500 | Loss: 0.94096, Acc: 74.22% | Test loss: 1.09825, Test acc: 63.81\n",
            "Epoch: 1600 | Loss: 1.05223, Acc: 63.25% | Test loss: 1.25264, Test acc: 48.57\n",
            "Epoch: 1700 | Loss: 0.75989, Acc: 79.71% | Test loss: 0.93717, Test acc: 71.43\n",
            "Epoch: 1800 | Loss: 0.64728, Acc: 84.73% | Test loss: 0.82392, Test acc: 71.43\n",
            "Epoch: 1900 | Loss: 0.56470, Acc: 86.40% | Test loss: 0.74858, Test acc: 74.29\n",
            "Epoch: 2000 | Loss: 0.48761, Acc: 88.78% | Test loss: 0.67870, Test acc: 76.19\n",
            "Epoch: 2100 | Loss: 0.42123, Acc: 90.69% | Test loss: 0.62101, Test acc: 80.95\n",
            "Epoch: 2200 | Loss: 0.36355, Acc: 92.12% | Test loss: 0.57342, Test acc: 82.86\n",
            "Epoch: 2300 | Loss: 0.31414, Acc: 93.56% | Test loss: 0.53514, Test acc: 83.81\n",
            "Epoch: 2400 | Loss: 0.27198, Acc: 95.23% | Test loss: 0.50475, Test acc: 84.76\n",
            "Epoch: 2500 | Loss: 0.23594, Acc: 96.42% | Test loss: 0.48084, Test acc: 84.76\n",
            "Epoch: 2600 | Loss: 0.20499, Acc: 96.90% | Test loss: 0.46202, Test acc: 86.67\n",
            "Epoch: 2700 | Loss: 0.17832, Acc: 96.90% | Test loss: 0.44706, Test acc: 86.67\n",
            "Epoch: 2800 | Loss: 0.15530, Acc: 97.61% | Test loss: 0.43499, Test acc: 88.57\n",
            "Epoch: 2900 | Loss: 0.13540, Acc: 98.09% | Test loss: 0.42515, Test acc: 89.52\n",
            "Epoch: 3000 | Loss: 0.11821, Acc: 98.33% | Test loss: 0.41707, Test acc: 89.52\n",
            "Epoch: 3100 | Loss: 0.10338, Acc: 99.28% | Test loss: 0.41042, Test acc: 90.48\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "epochs = 3200\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model_2.train()\n",
        "  y_logits = model_2(X_train)\n",
        "  y_pred = torch.softmax(y_logits, dim=1).argmax(dim=1)\n",
        "  loss = loss_fn(y_logits, y_train)\n",
        "  acc = accuracy_fn(y_train, y_pred)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  model_2.eval()\n",
        "  with torch.inference_mode():\n",
        "    test_logits = model_2(X_test)\n",
        "    test_pred = torch.softmax(test_logits, dim=1).argmax(dim=1)\n",
        "    test_loss = loss_fn(test_logits, y_test)\n",
        "    test_acc = accuracy_fn(y_test, test_pred)\n",
        "  if epoch % 100 == 0:\n",
        "    print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Acc: {acc:.2f}% | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(model_2.state_dict(), 'model2.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "4Snn0SN3F4Lp"
      },
      "outputs": [],
      "source": [
        "  with torch.inference_mode():\n",
        "    test_logits = model_2(X_test)\n",
        "    test_pred = torch.softmax(test_logits, dim=1).argmax(dim=1)\n",
        "    test_loss = loss_fn(test_logits, y_test)\n",
        "    test_acc = accuracy_fn(y_test, test_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VO3wRW3jESUN",
        "outputId": "dea19b77-7d6a-4796-da41-0c400a55639d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([408, 1536])\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2X30dKCOyp6",
        "outputId": "8fc48cdc-c224-40dd-d6fb-82157e7bc68c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 3199 | Loss: 0.09073, Acc: 99.76% | Test loss: 0.40503, Test acc: 89.52\n"
          ]
        }
      ],
      "source": [
        "print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Acc: {acc:.2f}% | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "0BezskqhX_7S"
      },
      "outputs": [],
      "source": [
        "test_indices = list(range(len(y_train), len(y_train) + len(y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2jVIxBWPYGK",
        "outputId": "df40f1de-8446-4e04-feaf-dd897f32cb91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 89.32%\n",
            "Number of Misclassifications: 11\n",
            "Name: ?mietanka 36% 500ml 1x5,99 5,99 | True Label: 5 | Predicted Label: 6\n",
            "Name: Ser mozarella 125g 1x4,99 4,99 | True Label: 5 | Predicted Label: 6\n",
            "Name: Jog. naturalny bio 200g 1x3,49 3,49 | True Label: 6 | Predicted Label: 5\n",
            "Name: Chleb pe?noziarn. 500g 1x4,99 4,99 | True Label: 6 | Predicted Label: 4\n",
            "Name: Makaron penne 500g 1x3,99 3,99 | True Label: 1 | Predicted Label: 5\n",
            "Name: Ry? parboiled 1kg 1x5,99 5,99 | True Label: 13 | Predicted Label: 7\n",
            "Name: Placki tortilla 6szt. 1x6,99 6,99 | True Label: 9 | Predicted Label: 12\n",
            "Name: Musli owocowe 500g 1x7,49 7,49 | True Label: 3 | Predicted Label: 7\n",
            "Name: Chrupki kukurydz. 200g 1x2,99 2,99 | True Label: 10 | Predicted Label: 12\n",
            "Name: Pieczywo razowe 400g 1x3,49 3,49 | True Label: 5 | Predicted Label: 1\n",
            "Name: M?ka pszenna typ 550 1kg 1x2,49 2,49 | True Label: 3 | Predicted Label: 7\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "misclassified_samples = []\n",
        "\n",
        "# Inside the training loop\n",
        "model_2.eval()\n",
        "with torch.inference_mode():\n",
        "    test_logits = model_2(X_test)\n",
        "    test_pred = torch.softmax(test_logits, dim=1).argmax(dim=1)\n",
        "    test_loss = loss_fn(test_logits, y_test)\n",
        "    test_acc = accuracy_fn(y_test, test_pred)\n",
        "\n",
        "    misclassified_indices = (test_pred != y_test).nonzero().squeeze()\n",
        "    misclassified_samples.extend([(X_test[i], y_test[i].item(), test_pred[i].item()) for i in misclassified_indices])\n",
        "\n",
        "# After the training loop\n",
        "print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
        "print(f\"Number of Misclassifications: {len(misclassified_samples)}\")\n",
        "\n",
        "# Attach names from the original DataFrame using Y_test_names\n",
        "misclassified_samples_with_names = [(X_sample, y_true, y_pred, Y_names_connected[test_indices[i]]) for i, (X_sample, y_true, y_pred) in enumerate(misclassified_samples)]\n",
        "\n",
        "for sample in misclassified_samples_with_names:\n",
        "    X_sample, y_true, y_pred, name = sample\n",
        "    print(f\"Name: {name} | True Label: {y_true} | Predicted Label: {y_pred}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jE7xMaMebhA",
        "outputId": "7cd30e22-2e88-40c7-db0a-7244ec025427"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    True Label  Predicted Label\n",
            "0            5                6\n",
            "1            5                6\n",
            "2            6                4\n",
            "3            2               10\n",
            "4            6                4\n",
            "5            1                5\n",
            "6            5                4\n",
            "7           13               10\n",
            "8            9               12\n",
            "9            3                7\n",
            "10           4                6\n",
            "11          10                9\n",
            "12           3                6\n",
            "13           2               10\n",
            "14          10                0\n",
            "15          12               11\n",
            "16           3                6\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "misclassified_samples = []\n",
        "\n",
        "# Inside the training loop\n",
        "model_2.eval()\n",
        "with torch.inference_mode():\n",
        "    test_logits = model_2(X_test)\n",
        "    test_pred = torch.softmax(test_logits, dim=1).argmax(dim=1)\n",
        "\n",
        "    misclassified_indices = (test_pred != y_test).nonzero().squeeze()\n",
        "    misclassified_samples.extend([(y_test[i].item(), test_pred[i].item()) for i in misclassified_indices])\n",
        "\n",
        "# Convert misclassified samples to a DataFrame\n",
        "misclassified_df = pd.DataFrame(misclassified_samples, columns=['True Label', 'Predicted Label'])\n",
        "\n",
        "# Print the misclassified samples\n",
        "print(misclassified_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(model_2.state_dict(), 'model.pth')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
